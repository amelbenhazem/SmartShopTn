# Guide Complet des Tests - SmartShop TN

Documentation exhaustive sur tous les types de tests, leur utilitÃ©, leur fonctionnement et leur exÃ©cution.

## ğŸ“š Table des MatiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Tests Unitaires (Jest)](#1-tests-unitaires-jest)
3. [Tests d'IntÃ©gration (Supertest)](#2-tests-dintÃ©gration-supertest)
4. [Tests E2E (Playwright)](#3-tests-e2e-playwright)
5. [Tests API (Postman/Newman)](#4-tests-api-postmannewman)
6. [Tests de Performance (JMeter)](#5-tests-de-performance-jmeter)
7. [Tests de QualitÃ© de Code (SonarQube)](#6-tests-de-qualitÃ©-de-code-sonarqube)
8. [Comparaison des Types de Tests](#comparaison-des-types-de-tests)
9. [StratÃ©gie de Test RecommandÃ©e](#stratÃ©gie-de-test-recommandÃ©e)

---

## Vue d'ensemble

### Pyramide de Tests

```
        /\
       /E2E\          â† Tests End-to-End (Peu nombreux, lents, coÃ»teux)
      /------\
     /  IntÃ©g  \      â† Tests d'IntÃ©gration (Moyen nombre, vitesse moyenne)
    /----------\
   /  Unitaires  \    â† Tests Unitaires (Nombreux, rapides, peu coÃ»teux)
  /--------------\
```

### Pourquoi Tester ?

- âœ… **DÃ©tecter les bugs** avant la production
- âœ… **Documenter** le comportement attendu
- âœ… **Faciliter la refactorisation** en toute sÃ©curitÃ©
- âœ… **AmÃ©liorer la qualitÃ©** du code
- âœ… **RÃ©duire les coÃ»ts** de maintenance
- âœ… **Augmenter la confiance** dans le code

---

## 1. Tests Unitaires (Jest)

### ğŸ¯ UtilitÃ©

Les tests unitaires vÃ©rifient le comportement d'une **unitÃ© isolÃ©e** de code (fonction, composant, classe) indÃ©pendamment du reste de l'application.

**Avantages :**
- âš¡ TrÃ¨s rapides (millisecondes)
- ğŸ¯ Faciles Ã  Ã©crire et maintenir
- ğŸ” Identifient prÃ©cisÃ©ment les bugs
- ğŸ“ Documentent le comportement attendu
- ğŸ”„ Permettent la refactorisation en sÃ©curitÃ©

**InconvÃ©nients :**
- âŒ Ne testent pas l'intÃ©gration entre composants
- âŒ Peuvent passer mÃªme si l'application ne fonctionne pas

### ğŸ”§ Comment Ã§a marche ?

1. **Isolation** : Chaque test est indÃ©pendant
2. **Mocking** : Les dÃ©pendances externes sont simulÃ©es
3. **Assertions** : VÃ©rification des rÃ©sultats attendus
4. **Coverage** : Mesure du pourcentage de code testÃ©

### ğŸ“ Exemple de Test Unitaire

**Backend** (`backend/tests/unit/jwt.test.js`):
```javascript
const { generateToken, verifyToken } = require('../../src/utils/jwt');

describe('JWT Utils', () => {
  it('should generate a valid token', () => {
    const userId = '123456';
    const token = generateToken(userId);
    
    expect(token).toBeDefined();
    expect(typeof token).toBe('string');
  });

  it('should verify a valid token', () => {
    const userId = '123456';
    const token = generateToken(userId);
    const decoded = verifyToken(token);
    
    expect(decoded.id).toBe(userId);
  });
});
```

**Frontend** (`frontend/src/tests/pages/AdminProducts.test.jsx`):
```javascript
import { render, screen, fireEvent } from '@testing-library/react';
import AdminProducts from '../../pages/AdminProducts';

describe('AdminProducts', () => {
  it('should display products list', async () => {
    render(<AdminProducts />);
    
    await waitFor(() => {
      expect(screen.getByText('Huile d\'olive')).toBeInTheDocument();
    });
  });
});
```

### ğŸš€ Comment ExÃ©cuter ?

#### Backend

```bash
# Tous les tests unitaires
cd backend
npm test

# Tests en mode watch (re-exÃ©cution automatique)
npm run test:watch

# Tests avec couverture de code
npm test -- --coverage

# Un fichier spÃ©cifique
npm test -- jwt.test.js

# Un test spÃ©cifique
npm test -- -t "should generate a valid token"
```

#### Frontend

```bash
# Tous les tests unitaires
cd frontend
npm test

# Tests en mode watch
npm run test:watch

# Tests avec couverture
npm run test:coverage

# Un fichier spÃ©cifique
npm test -- AdminProducts.test.jsx
```

### ğŸ“Š RÃ©sultats Attendus

```
PASS  tests/unit/jwt.test.js
  JWT Utils
    âœ“ should generate a valid token (5ms)
    âœ“ should verify a valid token (3ms)

Test Suites: 1 passed, 1 total
Tests:       2 passed, 2 total
Snapshots:   0 total
Time:        1.234 s
```

### ğŸ“ˆ Couverture de Code

```bash
# GÃ©nÃ©rer le rapport de couverture
npm test -- --coverage

# Ouvrir le rapport HTML
open coverage/lcov-report/index.html
```

**MÃ©triques importantes :**
- **Statements** : Pourcentage de lignes exÃ©cutÃ©es
- **Branches** : Pourcentage de branches testÃ©es (if/else)
- **Functions** : Pourcentage de fonctions appelÃ©es
- **Lines** : Pourcentage de lignes couvertes

**Objectif recommandÃ© :** > 80% de couverture

---

## 2. Tests d'IntÃ©gration (Supertest)

### ğŸ¯ UtilitÃ©

Les tests d'intÃ©gration vÃ©rifient que **plusieurs composants fonctionnent ensemble** correctement (ex: API + Base de donnÃ©es).

**Avantages :**
- ğŸ”— Testent l'intÃ©gration entre composants
- ğŸŒ VÃ©rifient les endpoints API complets
- ğŸ—„ï¸ Testent l'interaction avec la base de donnÃ©es
- ğŸ›¡ï¸ DÃ©tectent les problÃ¨mes d'intÃ©gration

**InconvÃ©nients :**
- â±ï¸ Plus lents que les tests unitaires
- ğŸ”§ Plus complexes Ã  configurer
- ğŸ—„ï¸ NÃ©cessitent une base de donnÃ©es de test

### ğŸ”§ Comment Ã§a marche ?

1. **Setup** : Configuration de l'environnement de test
2. **RequÃªte HTTP** : Simulation de requÃªtes API
3. **VÃ©rification** : Assertions sur les rÃ©ponses
4. **Cleanup** : Nettoyage aprÃ¨s chaque test

### ğŸ“ Exemple de Test d'IntÃ©gration

**Backend** (`backend/tests/integration/products.integration.test.js`):
```javascript
const request = require('supertest');
const app = require('../../src/server');
const Product = require('../../src/models/Product');

describe('Products API Integration', () => {
  let adminToken;

  beforeEach(async () => {
    // CrÃ©er un utilisateur admin de test
    const admin = await User.create({
      email: 'admin@test.com',
      password: 'admin123',
      role: 'admin'
    });
    adminToken = generateToken(admin._id);
  });

  it('should create a product', async () => {
    const productData = {
      name: 'Test Product',
      price: 25.00,
      category: 'Ã‰picerie',
      stock: 50
    };

    const response = await request(app)
      .post('/api/products')
      .set('Authorization', `Bearer ${adminToken}`)
      .send(productData)
      .expect(201);

    expect(response.body.product.name).toBe('Test Product');
  });

  it('should get all products', async () => {
    await Product.create({
      name: 'Product 1',
      price: 10,
      category: 'Ã‰picerie',
      stock: 100
    });

    const response = await request(app)
      .get('/api/products')
      .expect(200);

    expect(response.body.products.length).toBeGreaterThan(0);
  });
});
```

### ğŸš€ Comment ExÃ©cuter ?

```bash
# Tous les tests d'intÃ©gration
cd backend
npm run test:integration

# Un fichier spÃ©cifique
npm run test:integration -- products.integration.test.js

# Avec couverture
npm run test:integration -- --coverage
```

### ğŸ“Š RÃ©sultats Attendus

```
PASS  tests/integration/products.integration.test.js
  Products API Integration
    âœ“ should create a product (234ms)
    âœ“ should get all products (156ms)

Test Suites: 1 passed, 1 total
Tests:       2 passed, 2 total
Time:        2.456 s
```

### âš™ï¸ Configuration

**`backend/jest.config.js`**:
```javascript
module.exports = {
  testEnvironment: 'node',
  testMatch: ['**/tests/integration/**/*.test.js'],
  setupFilesAfterEnv: ['<rootDir>/tests/setup.js']
};
```

**`backend/tests/setup.js`**:
```javascript
// Configuration de la base de donnÃ©es de test
process.env.MONGODB_URI = 'mongodb://localhost:27017/smarthop-test';
process.env.JWT_SECRET = 'test-secret';
```

---

## 3. Tests E2E (Playwright)

### ğŸ¯ UtilitÃ©

Les tests E2E (End-to-End) simulent un **utilisateur rÃ©el** naviguant dans l'application complÃ¨te (frontend + backend).

**Avantages :**
- ğŸ‘¤ Testent du point de vue de l'utilisateur
- ğŸŒ VÃ©rifient l'application complÃ¨te
- ğŸ› DÃ©tectent les bugs d'intÃ©gration frontend/backend
- ğŸ“± Testent sur diffÃ©rents navigateurs

**InconvÃ©nients :**
- ğŸŒ TrÃ¨s lents (secondes par test)
- ğŸ’° CoÃ»teux en ressources
- ğŸ”§ Fragiles (dÃ©pendent de l'UI)
- ğŸ› Difficiles Ã  dÃ©boguer

### ğŸ”§ Comment Ã§a marche ?

1. **Lancement du navigateur** : Playwright ouvre un navigateur rÃ©el
2. **Navigation** : Simulation des actions utilisateur
3. **VÃ©rification** : Assertions sur l'Ã©tat de l'interface
4. **Screenshots** : Capture d'Ã©cran en cas d'Ã©chec

### ğŸ“ Exemple de Test E2E

**Frontend** (`frontend/tests/e2e/admin-products.spec.js`):
```javascript
import { test, expect } from '@playwright/test';

test.describe('Admin Products Management', () => {
  test.beforeEach(async ({ page }) => {
    // Login as admin
    await page.goto('/login');
    await page.fill('input[type="email"]', 'admin@smarthop.tn');
    await page.fill('input[type="password"]', 'admin123');
    await page.click('button[type="submit"]');
    await page.waitForURL('/');
  });

  test('should add a new product', async ({ page }) => {
    // Navigate to products page
    await page.goto('/admin/products');
    
    // Click add product button
    await page.click('text=+ Ajouter un produit');
    
    // Fill form
    await page.fill('input[name="name"]', 'Test Product E2E');
    await page.fill('input[name="price"]', '35.50');
    await page.selectOption('select[name="category"]', 'Ã‰picerie');
    await page.fill('input[name="stock"]', '100');
    
    // Submit
    await page.click('button:has-text("Ajouter")');
    
    // Verify product was added
    await expect(page.locator('text=Test Product E2E')).toBeVisible();
  });
});
```

### ğŸš€ Comment ExÃ©cuter ?

```bash
# Tous les tests E2E
cd frontend
npm run test:e2e

# Tests en mode UI (interface graphique)
npm run test:e2e:ui

# Un fichier spÃ©cifique
npm run test:e2e -- admin-products.spec.js

# Un test spÃ©cifique
npm run test:e2e -- -g "should add a new product"

# Tests sur un navigateur spÃ©cifique
npm run test:e2e -- --project=chromium

# Tests en mode headed (voir le navigateur)
npm run test:e2e -- --headed
```

### ğŸ“Š RÃ©sultats Attendus

```
Running 8 tests using 1 worker

  âœ“ admin-products.spec.js:5:3 â€º Admin Products Management â€º should add a new product (3.2s)
  âœ“ admin-products.spec.js:12:3 â€º Admin Products Management â€º should edit a product (2.8s)

  8 passed (45.2s)
```

### ğŸ“¸ Screenshots et VidÃ©os

Playwright capture automatiquement :
- **Screenshots** en cas d'Ã©chec
- **VidÃ©os** de l'exÃ©cution (si configurÃ©)
- **Traces** pour le dÃ©bogage

**Configuration** (`frontend/playwright.config.js`):
```javascript
export default {
  use: {
    screenshot: 'only-on-failure',
    video: 'retain-on-failure',
    trace: 'on-first-retry'
  }
};
```

### ğŸŒ Tests Multi-Navigateurs

```bash
# Tous les navigateurs
npm run test:e2e

# Chrome uniquement
npm run test:e2e -- --project=chromium

# Firefox uniquement
npm run test:e2e -- --project=firefox

# Safari uniquement
npm run test:e2e -- --project=webkit
```

---

## 4. Tests API (Postman/Newman)

### ğŸ¯ UtilitÃ©

Les tests API vÃ©rifient les **endpoints REST** indÃ©pendamment du frontend, avec des scÃ©narios complets et des assertions automatiques.

**Avantages :**
- ğŸŒ Testent les API sans frontend
- ğŸ“ Documentation interactive
- ğŸ”„ Faciles Ã  partager et rÃ©utiliser
- ğŸš€ ExÃ©cution rapide
- ğŸ“Š Rapports dÃ©taillÃ©s

**InconvÃ©nients :**
- ğŸ¨ Ne testent pas l'interface utilisateur
- ğŸ”§ NÃ©cessitent une configuration

### ğŸ”§ Comment Ã§a marche ?

1. **Collection** : Groupe de requÃªtes API
2. **Environnement** : Variables (URL, tokens, etc.)
3. **Tests** : Scripts JavaScript pour assertions
4. **ExÃ©cution** : Postman GUI ou Newman CLI

### ğŸ“ Exemple de Test API

**Postman Collection** (`postman/SmartShop-TN.postman_collection.json`):
```json
{
  "name": "Create Product (Admin)",
  "request": {
    "method": "POST",
    "header": [
      {
        "key": "Authorization",
        "value": "Bearer {{admin_token}}"
      }
    ],
    "body": {
      "mode": "raw",
      "raw": "{\n  \"name\": \"Nouveau Produit\",\n  \"price\": 25.00\n}"
    },
    "url": "{{base_url}}/api/products"
  },
  "event": [
    {
      "listen": "test",
      "script": {
        "exec": [
          "pm.test(\"Status code is 201\", function () {",
          "    pm.response.to.have.status(201);",
          "});",
          "",
          "pm.test(\"Product created\", function () {",
          "    var jsonData = pm.response.json();",
          "    pm.expect(jsonData.product).to.exist;",
          "    pm.environment.set(\"product_id\", jsonData.product._id);",
          "});"
        ]
      }
    }
  ]
}
```

### ğŸš€ Comment ExÃ©cuter ?

#### Avec Postman (Interface Graphique)

1. **Importer la collection** :
   - Ouvrir Postman
   - File â†’ Import
   - SÃ©lectionner `postman/SmartShop-TN.postman_collection.json`

2. **Configurer l'environnement** :
   - CrÃ©er un nouvel environnement
   - Ajouter les variables :
     - `base_url`: `http://localhost:3000`
     - `admin_token`: Token JWT de l'admin
     - `client_token`: Token JWT du client

3. **ExÃ©cuter** :
   - SÃ©lectionner la collection
   - Cliquer sur "Run"
   - Voir les rÃ©sultats

#### Avec Newman (Ligne de Commande)

```bash
# Installer Newman
npm install -g newman

# ExÃ©cuter la collection
newman run postman/SmartShop-TN.postman_collection.json \
  --environment postman/postman-environment.json

# Avec rapport HTML
newman run postman/SmartShop-TN.postman_collection.json \
  --environment postman/postman-environment.json \
  --reporters html \
  --reporter-html-export report.html

# Avec rapport JSON
newman run postman/SmartShop-TN.postman_collection.json \
  --environment postman/postman-environment.json \
  --reporters json \
  --reporter-json-export report.json

# Mode silencieux
newman run postman/SmartShop-TN.postman_collection.json \
  --environment postman/postman-environment.json \
  --silent
```

### ğŸ“Š RÃ©sultats Attendus

```
newman

SmartShop TN API Tests

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Create Product (Admin)                                â”‚
â”‚  POST http://localhost:3000/api/products               â”‚
â”‚                                                         â”‚
â”‚  âœ“ Status code is 201                                   â”‚
â”‚  âœ“ Product created                                      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Summary                                                â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                         â”‚ executed â”‚   failed â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚              iterations â”‚        1 â”‚        0 â”‚    â”‚
â”‚  â”‚                requests â”‚       15 â”‚        0 â”‚    â”‚
â”‚  â”‚            test-scripts â”‚       15 â”‚        0 â”‚    â”‚
â”‚  â”‚      prerequest-scripts â”‚        5 â”‚        0 â”‚    â”‚
â”‚  â”‚              assertions â”‚       30 â”‚        0 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ IntÃ©gration CI/CD

**`.github/workflows/postman.yml`**:
```yaml
name: Postman Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Install Newman
        run: npm install -g newman
      - name: Run Postman Tests
        run: |
          newman run postman/SmartShop-TN.postman_collection.json \
            --environment postman/postman-environment.json
```

---

## 5. Tests de Performance (JMeter)

### ğŸ¯ UtilitÃ©

Les tests de performance mesurent la **capacitÃ© de l'application** Ã  gÃ©rer la charge (utilisateurs simultanÃ©s, temps de rÃ©ponse, dÃ©bit).

**Avantages :**
- ğŸ“Š Identifient les goulots d'Ã©tranglement
- âš¡ Mesurent les temps de rÃ©ponse
- ğŸ‘¥ Testent la charge (utilisateurs simultanÃ©s)
- ğŸ“ˆ Aident Ã  dimensionner l'infrastructure

**InconvÃ©nients :**
- ğŸ”§ Configuration complexe
- ğŸ’» NÃ©cessitent des ressources
- â±ï¸ Tests longs Ã  exÃ©cuter

### ğŸ”§ Comment Ã§a marche ?

1. **Thread Group** : Groupe d'utilisateurs virtuels
2. **Samplers** : RequÃªtes HTTP Ã  tester
3. **Listeners** : Collecte des rÃ©sultats
4. **Assertions** : VÃ©rification des performances

### ğŸ“ Exemple de Test JMeter

**Fichier JMeter** (`jmeter/SmartShop-TN-Products-Tests.jmx`):
- **Thread Group** : 100 utilisateurs
- **Ramp-up** : 120 secondes
- **Loop Count** : 20 itÃ©rations
- **Sampler** : GET /api/products
- **Assertion** : Temps de rÃ©ponse < 1000ms

### ğŸš€ Comment ExÃ©cuter ?

#### Installation

```bash
# TÃ©lÃ©charger JMeter
# https://jmeter.apache.org/download_jmeter.cgi

# Ou avec Homebrew (Mac)
brew install jmeter

# Ou avec Chocolatey (Windows)
choco install jmeter
```

#### ExÃ©cution avec Interface Graphique

1. **Lancer JMeter** :
   ```bash
   jmeter
   ```

2. **Ouvrir le test plan** :
   - File â†’ Open
   - SÃ©lectionner `jmeter/SmartShop-TN-Products-Tests.jmx`

3. **Configurer les variables** :
   - Variables â†’ User Defined Variables
   - `base_url`: `http://localhost:3000`
   - `admin_token`: Token JWT de l'admin

4. **ExÃ©cuter** :
   - Run â†’ Start
   - Observer les rÃ©sultats en temps rÃ©el

5. **Voir les rÃ©sultats** :
   - View Results Tree : DÃ©tails de chaque requÃªte
   - Summary Report : Statistiques globales

#### ExÃ©cution en Ligne de Commande

```bash
# ExÃ©cuter le test plan
jmeter -n -t jmeter/SmartShop-TN-Products-Tests.jmx \
  -l results.jtl \
  -e -o report/

# Avec propriÃ©tÃ©s personnalisÃ©es
jmeter -n -t jmeter/SmartShop-TN-Products-Tests.jmx \
  -l results.jtl \
  -e -o report/ \
  -Jbase_url=http://localhost:3000 \
  -Jadmin_token=YOUR_TOKEN

# Mode GUI (pour dÃ©veloppement)
jmeter -t jmeter/SmartShop-TN-Products-Tests.jmx
```

### ğŸ“Š RÃ©sultats Attendus

**Summary Report**:
```
Summary Report
==============
Samples: 2000
Average: 234ms
Median: 198ms
90% Line: 456ms
95% Line: 567ms
99% Line: 789ms
Min: 45ms
Max: 1234ms
Error %: 0.0%
Throughput: 166.67/sec
```

**MÃ©triques importantes :**
- **Average** : Temps de rÃ©ponse moyen
- **Median** : Temps de rÃ©ponse mÃ©dian
- **90% Line** : 90% des requÃªtes sont plus rapides
- **Error %** : Pourcentage d'erreurs
- **Throughput** : RequÃªtes par seconde

### ğŸ“ˆ ScÃ©narios de Test

#### Load Test (Test de Charge)

**Objectif** : VÃ©rifier le comportement sous charge normale

**Configuration** :
- Utilisateurs : 50-100
- Ramp-up : 60-120 secondes
- DurÃ©e : 5-10 minutes

#### Stress Test (Test de Stress)

**Objectif** : Trouver la limite de l'application

**Configuration** :
- Utilisateurs : 200-500
- Ramp-up : 30-60 secondes
- DurÃ©e : Jusqu'Ã  Ã©chec

#### Spike Test (Test de Pic)

**Objectif** : VÃ©rifier le comportement lors d'un pic soudain

**Configuration** :
- Utilisateurs : 0 â†’ 200 â†’ 0
- Ramp-up : 10 secondes
- DurÃ©e : Court

### ğŸ” Analyse des RÃ©sultats

1. **Temps de rÃ©ponse** : Doit Ãªtre < 1000ms
2. **Taux d'erreur** : Doit Ãªtre < 1%
3. **DÃ©bit** : Doit Ãªtre suffisant pour la charge
4. **Utilisation CPU/MÃ©moire** : Doit rester raisonnable

---

## 6. Tests de QualitÃ© de Code (SonarQube)

### ğŸ¯ UtilitÃ©

SonarQube analyse le **code source** pour dÃ©tecter les bugs, vulnÃ©rabilitÃ©s, code smells et problÃ¨mes de qualitÃ©.

**Avantages :**
- ğŸ› DÃ©tecte les bugs avant l'exÃ©cution
- ğŸ”’ Identifie les vulnÃ©rabilitÃ©s de sÃ©curitÃ©
- ğŸ“Š Mesure la qualitÃ© du code
- ğŸ“ˆ Suit l'Ã©volution de la qualitÃ©
- ğŸ¯ Donne des recommandations

**InconvÃ©nients :**
- ğŸ”§ Configuration initiale complexe
- ğŸ’» NÃ©cessite un serveur SonarQube
- â±ï¸ Analyse peut Ãªtre longue

### ğŸ”§ Comment Ã§a marche ?

1. **Scanner** : Analyse le code source
2. **Analyse** : DÃ©tection des problÃ¨mes
3. **Rapport** : GÃ©nÃ©ration du rapport
4. **Dashboard** : Visualisation sur SonarQube

### ğŸš€ Comment Installer et Configurer ?

#### Option 1 : SonarQube Cloud (RecommandÃ©)

1. **CrÃ©er un compte** : https://sonarcloud.io
2. **CrÃ©er un projet**
3. **Obtenir le token**
4. **Configurer le scanner**

#### Option 2 : SonarQube Server (Local)

```bash
# TÃ©lÃ©charger SonarQube
# https://www.sonarqube.org/downloads/

# DÃ©marrer SonarQube
cd sonarqube/bin/linux-x86-64
./sonar.sh start

# AccÃ©der Ã  l'interface
# http://localhost:9000
# Login: admin / Password: admin
```

### ğŸ“ Configuration du Projet

#### Backend

**`backend/sonar-project.properties`**:
```properties
sonar.projectKey=smarthop-backend
sonar.projectName=SmartShop TN Backend
sonar.projectVersion=1.0
sonar.sources=src
sonar.tests=tests
sonar.javascript.lcov.reportPaths=coverage/lcov.info
sonar.coverage.exclusions=**/node_modules/**,**/tests/**
sonar.exclusions=**/node_modules/**,**/coverage/**
```

**`backend/package.json`**:
```json
{
  "scripts": {
    "sonar": "sonar-scanner"
  },
  "devDependencies": {
    "sonarqube-scanner": "^3.0.0"
  }
}
```

#### Frontend

**`frontend/sonar-project.properties`**:
```properties
sonar.projectKey=smarthop-frontend
sonar.projectName=SmartShop TN Frontend
sonar.projectVersion=1.0
sonar.sources=src
sonar.tests=src/tests
sonar.javascript.lcov.reportPaths=coverage/lcov.info
sonar.coverage.exclusions=**/node_modules/**,**/tests/**,**/*.test.jsx
sonar.exclusions=**/node_modules/**,**/coverage/**,**/dist/**
```

### ğŸš€ Comment ExÃ©cuter ?

#### Installation du Scanner

```bash
# Installer SonarQube Scanner
npm install -g sonarqube-scanner

# Ou avec Homebrew (Mac)
brew install sonar-scanner

# Ou avec Chocolatey (Windows)
choco install sonar-scanner
```

#### Configuration du Token

```bash
# CrÃ©er un token sur SonarQube
# Settings â†’ Security â†’ Generate Token

# Configurer le token
export SONAR_TOKEN=your_token_here

# Ou crÃ©er un fichier sonar-project.properties avec:
# sonar.login=your_token_here
```

#### ExÃ©cution de l'Analyse

**Backend**:
```bash
cd backend

# GÃ©nÃ©rer la couverture de code
npm test -- --coverage

# ExÃ©cuter SonarQube
sonar-scanner \
  -Dsonar.projectKey=smarthop-backend \
  -Dsonar.sources=src \
  -Dsonar.tests=tests \
  -Dsonar.javascript.lcov.reportPaths=coverage/lcov.info \
  -Dsonar.login=$SONAR_TOKEN
```

**Frontend**:
```bash
cd frontend

# GÃ©nÃ©rer la couverture de code
npm run test:coverage

# ExÃ©cuter SonarQube
sonar-scanner \
  -Dsonar.projectKey=smarthop-frontend \
  -Dsonar.sources=src \
  -Dsonar.tests=src/tests \
  -Dsonar.javascript.lcov.reportPaths=coverage/lcov.info \
  -Dsonar.login=$SONAR_TOKEN
```

#### Avec npm Scripts

**`backend/package.json`**:
```json
{
  "scripts": {
    "sonar": "npm test -- --coverage && sonar-scanner"
  }
}
```

```bash
cd backend
npm run sonar
```

### ğŸ“Š RÃ©sultats Attendus

**Dashboard SonarQube** affiche :

1. **Bugs** : Nombre de bugs dÃ©tectÃ©s
2. **VulnÃ©rabilitÃ©s** : ProblÃ¨mes de sÃ©curitÃ©
3. **Code Smells** : ProblÃ¨mes de qualitÃ©
4. **Coverage** : Pourcentage de code testÃ©
5. **Duplications** : Code dupliquÃ©
6. **Maintainability Rating** : Note de maintenabilitÃ©
7. **Reliability Rating** : Note de fiabilitÃ©
8. **Security Rating** : Note de sÃ©curitÃ©

**MÃ©triques importantes :**
- **Coverage** : > 80%
- **Duplications** : < 3%
- **Maintainability Rating** : A
- **Reliability Rating** : A
- **Security Rating** : A

### ğŸ” Types de ProblÃ¨mes DÃ©tectÃ©s

1. **Bugs** : Erreurs qui causeront un comportement incorrect
2. **VulnÃ©rabilitÃ©s** : Failles de sÃ©curitÃ©
3. **Code Smells** : ProblÃ¨mes de qualitÃ©/maintenabilitÃ©
4. **Duplications** : Code dupliquÃ©
5. **ComplexitÃ©** : Code trop complexe

### ğŸ“ˆ IntÃ©gration CI/CD

**`.github/workflows/sonar.yml`**:
```yaml
name: SonarQube Analysis

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  sonar:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v2
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: |
          cd backend && npm install
          cd ../frontend && npm install
      
      - name: Run tests with coverage
        run: |
          cd backend && npm test -- --coverage
          cd ../frontend && npm run test:coverage
      
      - name: SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
```

---

## Comparaison des Types de Tests

| Type | Vitesse | CoÃ»t | Couverture | ComplexitÃ© | Quand Utiliser |
|------|---------|------|------------|------------|----------------|
| **Unitaires** | âš¡âš¡âš¡ | ğŸ’° | ğŸ¯ Fonction | ğŸŸ¢ Facile | Toujours |
| **IntÃ©gration** | âš¡âš¡ | ğŸ’°ğŸ’° | ğŸ”— Composants | ğŸŸ¡ Moyen | FonctionnalitÃ©s critiques |
| **E2E** | âš¡ | ğŸ’°ğŸ’°ğŸ’° | ğŸŒ Application | ğŸ”´ Complexe | Workflows complets |
| **API** | âš¡âš¡âš¡ | ğŸ’° | ğŸŒ API | ğŸŸ¢ Facile | Endpoints API |
| **Performance** | âš¡ | ğŸ’°ğŸ’°ğŸ’° | âš¡ Performance | ğŸ”´ Complexe | Avant dÃ©ploiement |
| **SonarQube** | âš¡âš¡ | ğŸ’°ğŸ’° | ğŸ“Š QualitÃ© | ğŸŸ¡ Moyen | Analyse continue |

---

## StratÃ©gie de Test RecommandÃ©e

### ğŸ¯ Pyramide de Tests IdÃ©ale

```
        /\
       /E2E\          â† 5-10% : Tests critiques uniquement
      /------\
     /  IntÃ©g  \      â† 20-30% : FonctionnalitÃ©s importantes
    /----------\
   /  Unitaires  \    â† 60-70% : Toute la logique mÃ©tier
  /--------------\
```

### ğŸ“… Quand ExÃ©cuter Quels Tests ?

#### DÃ©veloppement Local
- âœ… Tests unitaires (Ã  chaque modification)
- âœ… Tests d'intÃ©gration (avant commit)
- âš ï¸ Tests E2E (avant push)

#### Pull Request
- âœ… Tous les tests unitaires
- âœ… Tous les tests d'intÃ©gration
- âœ… Tests E2E critiques
- âœ… Tests API
- âœ… SonarQube

#### Avant DÃ©ploiement
- âœ… Tous les tests
- âœ… Tests de performance
- âœ… SonarQube (qualitÃ© A)

#### Production
- âœ… Monitoring continu
- âœ… Tests de performance rÃ©guliers

### ğŸ¯ Objectifs de QualitÃ©

- **Couverture de code** : > 80%
- **Temps de rÃ©ponse** : < 1000ms
- **Taux d'erreur** : < 1%
- **SonarQube Rating** : A
- **Tests E2E** : 100% passÃ©s

---

## ğŸ“š Ressources

### Documentation Officielle

- [Jest](https://jestjs.io/docs/getting-started)
- [Supertest](https://github.com/visionmedia/supertest)
- [Playwright](https://playwright.dev/)
- [Postman](https://learning.postman.com/)
- [JMeter](https://jmeter.apache.org/usermanual/)
- [SonarQube](https://docs.sonarqube.org/)

### Outils ComplÃ©mentaires

- **ESLint** : Analyse statique du code JavaScript
- **Prettier** : Formatage automatique
- **Husky** : Git hooks pour exÃ©cuter les tests
- **Coveralls** : Suivi de la couverture de code

---

## âœ… Checklist de Tests

### Avant chaque Commit
- [ ] Tests unitaires passent
- [ ] Pas de warnings ESLint
- [ ] Code formatÃ© avec Prettier

### Avant chaque Pull Request
- [ ] Tous les tests unitaires passent
- [ ] Tests d'intÃ©gration passent
- [ ] Tests E2E critiques passent
- [ ] SonarQube sans nouveaux problÃ¨mes

### Avant chaque DÃ©ploiement
- [ ] Tous les tests passent
- [ ] Tests de performance validÃ©s
- [ ] SonarQube Rating A
- [ ] Documentation Ã  jour

---

## ğŸ†˜ DÃ©pannage

### Tests unitaires Ã©chouent
```bash
# VÃ©rifier les mocks
# VÃ©rifier les imports
# VÃ©rifier les dÃ©pendances
npm install
```

### Tests E2E Ã©chouent
```bash
# VÃ©rifier que le serveur est dÃ©marrÃ©
# VÃ©rifier les sÃ©lecteurs
# VÃ©rifier les timeouts
npm run test:e2e -- --debug
```

### SonarQube ne fonctionne pas
```bash
# VÃ©rifier le token
# VÃ©rifier la configuration
# VÃ©rifier la connexion au serveur
sonar-scanner -X  # Mode debug
```

---

**DerniÃ¨re mise Ã  jour** : 2024
**Version** : 1.0

